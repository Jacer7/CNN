{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Audio Genre Classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMYLCdG0mWJtEt1Z95Eseuy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jacer7/CNN/blob/main/Audio_Genre_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "6sldECcgCOzz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "lk7fl-FCCQ_l"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m36ZrxzOCSte",
        "outputId": "1e024c8a-8fbf-4d41-cbad-2f62287da4c7"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "   df = pd.read_csv('/content/drive/MyDrive/Hiring Challenge - Data Scientist Audio Internship/part3_GrooverChallengeDataset.csv')\n",
        "   df.head(2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "9sWMX1PYEVAo",
        "outputId": "0e52375d-8914-473b-c6ba-8cf01f9769ed"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>length</th>\n",
              "      <th>chroma_stft_mean</th>\n",
              "      <th>chroma_stft_var</th>\n",
              "      <th>rms_mean</th>\n",
              "      <th>rms_var</th>\n",
              "      <th>spectral_centroid_mean</th>\n",
              "      <th>spectral_centroid_var</th>\n",
              "      <th>spectral_bandwidth_mean</th>\n",
              "      <th>spectral_bandwidth_var</th>\n",
              "      <th>rolloff_mean</th>\n",
              "      <th>rolloff_var</th>\n",
              "      <th>zero_crossing_rate_mean</th>\n",
              "      <th>zero_crossing_rate_var</th>\n",
              "      <th>harmony_mean</th>\n",
              "      <th>harmony_var</th>\n",
              "      <th>perceptr_mean</th>\n",
              "      <th>perceptr_var</th>\n",
              "      <th>tempo</th>\n",
              "      <th>mfcc1_mean</th>\n",
              "      <th>mfcc1_var</th>\n",
              "      <th>mfcc2_mean</th>\n",
              "      <th>mfcc2_var</th>\n",
              "      <th>mfcc3_mean</th>\n",
              "      <th>mfcc3_var</th>\n",
              "      <th>mfcc4_mean</th>\n",
              "      <th>mfcc4_var</th>\n",
              "      <th>mfcc5_mean</th>\n",
              "      <th>mfcc5_var</th>\n",
              "      <th>mfcc6_mean</th>\n",
              "      <th>mfcc6_var</th>\n",
              "      <th>mfcc7_mean</th>\n",
              "      <th>mfcc7_var</th>\n",
              "      <th>mfcc8_mean</th>\n",
              "      <th>mfcc8_var</th>\n",
              "      <th>mfcc9_mean</th>\n",
              "      <th>mfcc9_var</th>\n",
              "      <th>mfcc10_mean</th>\n",
              "      <th>mfcc10_var</th>\n",
              "      <th>mfcc11_mean</th>\n",
              "      <th>mfcc11_var</th>\n",
              "      <th>mfcc12_mean</th>\n",
              "      <th>mfcc12_var</th>\n",
              "      <th>mfcc13_mean</th>\n",
              "      <th>mfcc13_var</th>\n",
              "      <th>mfcc14_mean</th>\n",
              "      <th>mfcc14_var</th>\n",
              "      <th>mfcc15_mean</th>\n",
              "      <th>mfcc15_var</th>\n",
              "      <th>mfcc16_mean</th>\n",
              "      <th>mfcc16_var</th>\n",
              "      <th>mfcc17_mean</th>\n",
              "      <th>mfcc17_var</th>\n",
              "      <th>mfcc18_mean</th>\n",
              "      <th>mfcc18_var</th>\n",
              "      <th>mfcc19_mean</th>\n",
              "      <th>mfcc19_var</th>\n",
              "      <th>mfcc20_mean</th>\n",
              "      <th>mfcc20_var</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>661794</td>\n",
              "      <td>0.350088</td>\n",
              "      <td>0.088757</td>\n",
              "      <td>0.130228</td>\n",
              "      <td>0.002827</td>\n",
              "      <td>1784.165850</td>\n",
              "      <td>129774.064525</td>\n",
              "      <td>2002.449060</td>\n",
              "      <td>85882.761315</td>\n",
              "      <td>3805.839606</td>\n",
              "      <td>9.015054e+05</td>\n",
              "      <td>0.083045</td>\n",
              "      <td>0.000767</td>\n",
              "      <td>-0.000045</td>\n",
              "      <td>0.008172</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.005698</td>\n",
              "      <td>123.046875</td>\n",
              "      <td>-113.570648</td>\n",
              "      <td>2564.207520</td>\n",
              "      <td>121.571793</td>\n",
              "      <td>295.913818</td>\n",
              "      <td>-19.168142</td>\n",
              "      <td>235.574432</td>\n",
              "      <td>42.366421</td>\n",
              "      <td>151.106873</td>\n",
              "      <td>-6.364664</td>\n",
              "      <td>167.934799</td>\n",
              "      <td>18.623499</td>\n",
              "      <td>89.180840</td>\n",
              "      <td>-13.704891</td>\n",
              "      <td>67.660492</td>\n",
              "      <td>15.343150</td>\n",
              "      <td>68.932579</td>\n",
              "      <td>-12.274110</td>\n",
              "      <td>82.204201</td>\n",
              "      <td>10.976572</td>\n",
              "      <td>63.386311</td>\n",
              "      <td>-8.326573</td>\n",
              "      <td>61.773094</td>\n",
              "      <td>8.803792</td>\n",
              "      <td>51.244125</td>\n",
              "      <td>-3.67230</td>\n",
              "      <td>41.217415</td>\n",
              "      <td>5.747995</td>\n",
              "      <td>40.554478</td>\n",
              "      <td>-5.162882</td>\n",
              "      <td>49.775421</td>\n",
              "      <td>0.752740</td>\n",
              "      <td>52.420910</td>\n",
              "      <td>-1.690215</td>\n",
              "      <td>36.524071</td>\n",
              "      <td>-0.408979</td>\n",
              "      <td>41.597103</td>\n",
              "      <td>-2.303523</td>\n",
              "      <td>55.062923</td>\n",
              "      <td>1.221291</td>\n",
              "      <td>46.936035</td>\n",
              "      <td>blues</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>661794</td>\n",
              "      <td>0.340914</td>\n",
              "      <td>0.094980</td>\n",
              "      <td>0.095948</td>\n",
              "      <td>0.002373</td>\n",
              "      <td>1530.176679</td>\n",
              "      <td>375850.073649</td>\n",
              "      <td>2039.036516</td>\n",
              "      <td>213843.755497</td>\n",
              "      <td>3550.522098</td>\n",
              "      <td>2.977893e+06</td>\n",
              "      <td>0.056040</td>\n",
              "      <td>0.001448</td>\n",
              "      <td>0.000140</td>\n",
              "      <td>0.005099</td>\n",
              "      <td>-0.000178</td>\n",
              "      <td>0.003063</td>\n",
              "      <td>67.999589</td>\n",
              "      <td>-207.501694</td>\n",
              "      <td>7764.555176</td>\n",
              "      <td>123.991264</td>\n",
              "      <td>560.259949</td>\n",
              "      <td>8.955127</td>\n",
              "      <td>572.810913</td>\n",
              "      <td>35.877647</td>\n",
              "      <td>264.506104</td>\n",
              "      <td>2.907320</td>\n",
              "      <td>279.932922</td>\n",
              "      <td>21.510466</td>\n",
              "      <td>156.477097</td>\n",
              "      <td>-8.560436</td>\n",
              "      <td>200.849182</td>\n",
              "      <td>23.370686</td>\n",
              "      <td>142.555954</td>\n",
              "      <td>-10.099661</td>\n",
              "      <td>166.108521</td>\n",
              "      <td>11.900497</td>\n",
              "      <td>104.358612</td>\n",
              "      <td>-5.555639</td>\n",
              "      <td>105.173630</td>\n",
              "      <td>5.376327</td>\n",
              "      <td>96.197212</td>\n",
              "      <td>-2.23176</td>\n",
              "      <td>64.914291</td>\n",
              "      <td>4.220140</td>\n",
              "      <td>73.152534</td>\n",
              "      <td>-6.012148</td>\n",
              "      <td>52.422142</td>\n",
              "      <td>0.927998</td>\n",
              "      <td>55.356403</td>\n",
              "      <td>-0.731125</td>\n",
              "      <td>60.314529</td>\n",
              "      <td>0.295073</td>\n",
              "      <td>48.120598</td>\n",
              "      <td>-0.283518</td>\n",
              "      <td>51.106190</td>\n",
              "      <td>0.531217</td>\n",
              "      <td>45.786282</td>\n",
              "      <td>blues</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   length  chroma_stft_mean  chroma_stft_var  ...  mfcc20_mean  mfcc20_var  label\n",
              "0  661794          0.350088         0.088757  ...     1.221291   46.936035  blues\n",
              "1  661794          0.340914         0.094980  ...     0.531217   45.786282  blues\n",
              "\n",
              "[2 rows x 59 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning"
      ],
      "metadata": {
        "id": "p_BlttvXFzWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()"
      ],
      "metadata": {
        "id": "9Vei2vt2FyGa"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'] = le.fit_transform(df['label'])"
      ],
      "metadata": {
        "id": "NNPuI4xXF_Oa"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "id": "8j1BMh58CIhI",
        "outputId": "1c8f3008-f881-4400-a410-e93e54cb09ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        }
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>length</th>\n",
              "      <th>chroma_stft_mean</th>\n",
              "      <th>chroma_stft_var</th>\n",
              "      <th>rms_mean</th>\n",
              "      <th>rms_var</th>\n",
              "      <th>spectral_centroid_mean</th>\n",
              "      <th>spectral_centroid_var</th>\n",
              "      <th>spectral_bandwidth_mean</th>\n",
              "      <th>spectral_bandwidth_var</th>\n",
              "      <th>rolloff_mean</th>\n",
              "      <th>rolloff_var</th>\n",
              "      <th>zero_crossing_rate_mean</th>\n",
              "      <th>zero_crossing_rate_var</th>\n",
              "      <th>harmony_mean</th>\n",
              "      <th>harmony_var</th>\n",
              "      <th>perceptr_mean</th>\n",
              "      <th>perceptr_var</th>\n",
              "      <th>tempo</th>\n",
              "      <th>mfcc1_mean</th>\n",
              "      <th>mfcc1_var</th>\n",
              "      <th>mfcc2_mean</th>\n",
              "      <th>mfcc2_var</th>\n",
              "      <th>mfcc3_mean</th>\n",
              "      <th>mfcc3_var</th>\n",
              "      <th>mfcc4_mean</th>\n",
              "      <th>mfcc4_var</th>\n",
              "      <th>mfcc5_mean</th>\n",
              "      <th>mfcc5_var</th>\n",
              "      <th>mfcc6_mean</th>\n",
              "      <th>mfcc6_var</th>\n",
              "      <th>mfcc7_mean</th>\n",
              "      <th>mfcc7_var</th>\n",
              "      <th>mfcc8_mean</th>\n",
              "      <th>mfcc8_var</th>\n",
              "      <th>mfcc9_mean</th>\n",
              "      <th>mfcc9_var</th>\n",
              "      <th>mfcc10_mean</th>\n",
              "      <th>mfcc10_var</th>\n",
              "      <th>mfcc11_mean</th>\n",
              "      <th>mfcc11_var</th>\n",
              "      <th>mfcc12_mean</th>\n",
              "      <th>mfcc12_var</th>\n",
              "      <th>mfcc13_mean</th>\n",
              "      <th>mfcc13_var</th>\n",
              "      <th>mfcc14_mean</th>\n",
              "      <th>mfcc14_var</th>\n",
              "      <th>mfcc15_mean</th>\n",
              "      <th>mfcc15_var</th>\n",
              "      <th>mfcc16_mean</th>\n",
              "      <th>mfcc16_var</th>\n",
              "      <th>mfcc17_mean</th>\n",
              "      <th>mfcc17_var</th>\n",
              "      <th>mfcc18_mean</th>\n",
              "      <th>mfcc18_var</th>\n",
              "      <th>mfcc19_mean</th>\n",
              "      <th>mfcc19_var</th>\n",
              "      <th>mfcc20_mean</th>\n",
              "      <th>mfcc20_var</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>661794</td>\n",
              "      <td>0.350088</td>\n",
              "      <td>0.088757</td>\n",
              "      <td>0.130228</td>\n",
              "      <td>0.002827</td>\n",
              "      <td>1784.165850</td>\n",
              "      <td>129774.064525</td>\n",
              "      <td>2002.449060</td>\n",
              "      <td>85882.761315</td>\n",
              "      <td>3805.839606</td>\n",
              "      <td>9.015054e+05</td>\n",
              "      <td>0.083045</td>\n",
              "      <td>0.000767</td>\n",
              "      <td>-4.529724e-05</td>\n",
              "      <td>0.008172</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.005698</td>\n",
              "      <td>123.046875</td>\n",
              "      <td>-113.570648</td>\n",
              "      <td>2564.207520</td>\n",
              "      <td>121.571793</td>\n",
              "      <td>295.913818</td>\n",
              "      <td>-19.168142</td>\n",
              "      <td>235.574432</td>\n",
              "      <td>42.366421</td>\n",
              "      <td>151.106873</td>\n",
              "      <td>-6.364664</td>\n",
              "      <td>167.934799</td>\n",
              "      <td>18.623499</td>\n",
              "      <td>89.180840</td>\n",
              "      <td>-13.704891</td>\n",
              "      <td>67.660492</td>\n",
              "      <td>15.343150</td>\n",
              "      <td>68.932579</td>\n",
              "      <td>-12.274110</td>\n",
              "      <td>82.204201</td>\n",
              "      <td>10.976572</td>\n",
              "      <td>63.386311</td>\n",
              "      <td>-8.326573</td>\n",
              "      <td>61.773094</td>\n",
              "      <td>8.803792</td>\n",
              "      <td>51.244125</td>\n",
              "      <td>-3.672300</td>\n",
              "      <td>41.217415</td>\n",
              "      <td>5.747995</td>\n",
              "      <td>40.554478</td>\n",
              "      <td>-5.162882</td>\n",
              "      <td>49.775421</td>\n",
              "      <td>0.752740</td>\n",
              "      <td>52.420910</td>\n",
              "      <td>-1.690215</td>\n",
              "      <td>36.524071</td>\n",
              "      <td>-0.408979</td>\n",
              "      <td>41.597103</td>\n",
              "      <td>-2.303523</td>\n",
              "      <td>55.062923</td>\n",
              "      <td>1.221291</td>\n",
              "      <td>46.936035</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>661794</td>\n",
              "      <td>0.340914</td>\n",
              "      <td>0.094980</td>\n",
              "      <td>0.095948</td>\n",
              "      <td>0.002373</td>\n",
              "      <td>1530.176679</td>\n",
              "      <td>375850.073649</td>\n",
              "      <td>2039.036516</td>\n",
              "      <td>213843.755497</td>\n",
              "      <td>3550.522098</td>\n",
              "      <td>2.977893e+06</td>\n",
              "      <td>0.056040</td>\n",
              "      <td>0.001448</td>\n",
              "      <td>1.395807e-04</td>\n",
              "      <td>0.005099</td>\n",
              "      <td>-0.000178</td>\n",
              "      <td>0.003063</td>\n",
              "      <td>67.999589</td>\n",
              "      <td>-207.501694</td>\n",
              "      <td>7764.555176</td>\n",
              "      <td>123.991264</td>\n",
              "      <td>560.259949</td>\n",
              "      <td>8.955127</td>\n",
              "      <td>572.810913</td>\n",
              "      <td>35.877647</td>\n",
              "      <td>264.506104</td>\n",
              "      <td>2.907320</td>\n",
              "      <td>279.932922</td>\n",
              "      <td>21.510466</td>\n",
              "      <td>156.477097</td>\n",
              "      <td>-8.560436</td>\n",
              "      <td>200.849182</td>\n",
              "      <td>23.370686</td>\n",
              "      <td>142.555954</td>\n",
              "      <td>-10.099661</td>\n",
              "      <td>166.108521</td>\n",
              "      <td>11.900497</td>\n",
              "      <td>104.358612</td>\n",
              "      <td>-5.555639</td>\n",
              "      <td>105.173630</td>\n",
              "      <td>5.376327</td>\n",
              "      <td>96.197212</td>\n",
              "      <td>-2.231760</td>\n",
              "      <td>64.914291</td>\n",
              "      <td>4.220140</td>\n",
              "      <td>73.152534</td>\n",
              "      <td>-6.012148</td>\n",
              "      <td>52.422142</td>\n",
              "      <td>0.927998</td>\n",
              "      <td>55.356403</td>\n",
              "      <td>-0.731125</td>\n",
              "      <td>60.314529</td>\n",
              "      <td>0.295073</td>\n",
              "      <td>48.120598</td>\n",
              "      <td>-0.283518</td>\n",
              "      <td>51.106190</td>\n",
              "      <td>0.531217</td>\n",
              "      <td>45.786282</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>661794</td>\n",
              "      <td>0.363637</td>\n",
              "      <td>0.085275</td>\n",
              "      <td>0.175570</td>\n",
              "      <td>0.002746</td>\n",
              "      <td>1552.811865</td>\n",
              "      <td>156467.643368</td>\n",
              "      <td>1747.702312</td>\n",
              "      <td>76254.192257</td>\n",
              "      <td>3042.260232</td>\n",
              "      <td>7.840345e+05</td>\n",
              "      <td>0.076291</td>\n",
              "      <td>0.001007</td>\n",
              "      <td>2.105576e-06</td>\n",
              "      <td>0.016342</td>\n",
              "      <td>-0.000019</td>\n",
              "      <td>0.007458</td>\n",
              "      <td>161.499023</td>\n",
              "      <td>-90.722595</td>\n",
              "      <td>3319.044922</td>\n",
              "      <td>140.446304</td>\n",
              "      <td>508.765045</td>\n",
              "      <td>-29.093889</td>\n",
              "      <td>411.781219</td>\n",
              "      <td>31.684334</td>\n",
              "      <td>144.090317</td>\n",
              "      <td>-13.984504</td>\n",
              "      <td>155.493759</td>\n",
              "      <td>25.764742</td>\n",
              "      <td>74.548401</td>\n",
              "      <td>-13.664875</td>\n",
              "      <td>106.981827</td>\n",
              "      <td>11.639934</td>\n",
              "      <td>106.574875</td>\n",
              "      <td>-11.783643</td>\n",
              "      <td>65.447945</td>\n",
              "      <td>9.718760</td>\n",
              "      <td>67.908859</td>\n",
              "      <td>-13.133803</td>\n",
              "      <td>57.781425</td>\n",
              "      <td>5.791199</td>\n",
              "      <td>64.480209</td>\n",
              "      <td>-8.907628</td>\n",
              "      <td>60.385151</td>\n",
              "      <td>-1.077000</td>\n",
              "      <td>57.711136</td>\n",
              "      <td>-9.229274</td>\n",
              "      <td>36.580986</td>\n",
              "      <td>2.451690</td>\n",
              "      <td>40.598766</td>\n",
              "      <td>-7.729093</td>\n",
              "      <td>47.639427</td>\n",
              "      <td>-1.816407</td>\n",
              "      <td>52.382141</td>\n",
              "      <td>-3.439720</td>\n",
              "      <td>46.639660</td>\n",
              "      <td>-2.231258</td>\n",
              "      <td>30.573025</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>661794</td>\n",
              "      <td>0.404785</td>\n",
              "      <td>0.093999</td>\n",
              "      <td>0.141093</td>\n",
              "      <td>0.006346</td>\n",
              "      <td>1070.106615</td>\n",
              "      <td>184355.942417</td>\n",
              "      <td>1596.412872</td>\n",
              "      <td>166441.494769</td>\n",
              "      <td>2184.745799</td>\n",
              "      <td>1.493194e+06</td>\n",
              "      <td>0.033309</td>\n",
              "      <td>0.000423</td>\n",
              "      <td>4.583644e-07</td>\n",
              "      <td>0.019054</td>\n",
              "      <td>-0.000014</td>\n",
              "      <td>0.002712</td>\n",
              "      <td>63.024009</td>\n",
              "      <td>-199.544205</td>\n",
              "      <td>5507.517090</td>\n",
              "      <td>150.090897</td>\n",
              "      <td>456.505402</td>\n",
              "      <td>5.662678</td>\n",
              "      <td>257.161163</td>\n",
              "      <td>26.859079</td>\n",
              "      <td>158.267303</td>\n",
              "      <td>1.771399</td>\n",
              "      <td>268.034393</td>\n",
              "      <td>14.234031</td>\n",
              "      <td>126.794128</td>\n",
              "      <td>-4.832006</td>\n",
              "      <td>155.912079</td>\n",
              "      <td>9.286494</td>\n",
              "      <td>81.273743</td>\n",
              "      <td>-0.759186</td>\n",
              "      <td>92.114090</td>\n",
              "      <td>8.137607</td>\n",
              "      <td>71.314079</td>\n",
              "      <td>-3.200653</td>\n",
              "      <td>110.236687</td>\n",
              "      <td>6.079319</td>\n",
              "      <td>48.251999</td>\n",
              "      <td>-2.480174</td>\n",
              "      <td>56.799400</td>\n",
              "      <td>-1.079305</td>\n",
              "      <td>62.289902</td>\n",
              "      <td>-2.870789</td>\n",
              "      <td>51.651592</td>\n",
              "      <td>0.780874</td>\n",
              "      <td>44.427753</td>\n",
              "      <td>-3.319597</td>\n",
              "      <td>50.206673</td>\n",
              "      <td>0.636965</td>\n",
              "      <td>37.319130</td>\n",
              "      <td>-0.619121</td>\n",
              "      <td>37.259739</td>\n",
              "      <td>-3.407448</td>\n",
              "      <td>31.949339</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>661794</td>\n",
              "      <td>0.308526</td>\n",
              "      <td>0.087841</td>\n",
              "      <td>0.091529</td>\n",
              "      <td>0.002303</td>\n",
              "      <td>1835.004266</td>\n",
              "      <td>343399.939274</td>\n",
              "      <td>1748.172116</td>\n",
              "      <td>88445.209036</td>\n",
              "      <td>3579.757627</td>\n",
              "      <td>1.572978e+06</td>\n",
              "      <td>0.101461</td>\n",
              "      <td>0.001954</td>\n",
              "      <td>-1.756129e-05</td>\n",
              "      <td>0.004814</td>\n",
              "      <td>-0.000010</td>\n",
              "      <td>0.003094</td>\n",
              "      <td>135.999178</td>\n",
              "      <td>-160.337708</td>\n",
              "      <td>5195.291992</td>\n",
              "      <td>126.219635</td>\n",
              "      <td>853.784729</td>\n",
              "      <td>-35.587811</td>\n",
              "      <td>333.792938</td>\n",
              "      <td>22.148071</td>\n",
              "      <td>193.456100</td>\n",
              "      <td>-32.478600</td>\n",
              "      <td>336.276825</td>\n",
              "      <td>10.852294</td>\n",
              "      <td>134.831573</td>\n",
              "      <td>-23.352329</td>\n",
              "      <td>93.257095</td>\n",
              "      <td>0.498434</td>\n",
              "      <td>124.672127</td>\n",
              "      <td>-11.793437</td>\n",
              "      <td>130.073349</td>\n",
              "      <td>1.207256</td>\n",
              "      <td>99.675575</td>\n",
              "      <td>-13.088418</td>\n",
              "      <td>80.254066</td>\n",
              "      <td>-2.813867</td>\n",
              "      <td>86.430626</td>\n",
              "      <td>-6.933385</td>\n",
              "      <td>89.555443</td>\n",
              "      <td>-7.552725</td>\n",
              "      <td>70.943336</td>\n",
              "      <td>-9.164666</td>\n",
              "      <td>75.793404</td>\n",
              "      <td>-4.520576</td>\n",
              "      <td>86.099236</td>\n",
              "      <td>-5.454034</td>\n",
              "      <td>75.269707</td>\n",
              "      <td>-0.916874</td>\n",
              "      <td>53.613918</td>\n",
              "      <td>-4.404827</td>\n",
              "      <td>62.910812</td>\n",
              "      <td>-11.703234</td>\n",
              "      <td>55.195160</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   length  chroma_stft_mean  chroma_stft_var  ...  mfcc20_mean  mfcc20_var  label\n",
              "0  661794          0.350088         0.088757  ...     1.221291   46.936035      0\n",
              "1  661794          0.340914         0.094980  ...     0.531217   45.786282      0\n",
              "2  661794          0.363637         0.085275  ...    -2.231258   30.573025      0\n",
              "3  661794          0.404785         0.093999  ...    -3.407448   31.949339      0\n",
              "4  661794          0.308526         0.087841  ...   -11.703234   55.195160      0\n",
              "\n",
              "[5 rows x 59 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "le.classes_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8BB772SGW69",
        "outputId": "5261f1ff-1482-4072-b90f-47ffad58962d"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz',\n",
              "       'metal', 'pop', 'reggae', 'rock'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "le.inverse_transform([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuBWhVJDGZ3Y",
        "outputId": "c1d731e4-62d4-4e18-da71-f973c8ef23db"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz',\n",
              "       'metal', 'pop', 'reggae', 'rock'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert DataFrame into Array\n",
        "X_frame = df.drop(['label'], axis=1)\n",
        "X_data = X_frame.to_numpy().astype(float)\n",
        "X_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKx96bw2Gmry",
        "outputId": "ef8f7de2-db86-4abd-a19a-fe86065bf2bf"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 58)"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standarize the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler().fit(X_data)\n",
        "X_data = scaler.transform(X_data)"
      ],
      "metadata": {
        "id": "7NS-naCTCZNN"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_data = df['label']"
      ],
      "metadata": {
        "id": "ETHidUI-Djyr"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Since the target data is multi class of 10, we we one-hot-encoding and create an array of 10 columns\n",
        "y_data = tf.keras.utils.to_categorical(y_data, 10)"
      ],
      "metadata": {
        "id": "MOP81bvPDNjd"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nfeatures after scaling:\\n----------------\")\n",
        "print(X_data[:1,:])\n",
        "print(\"\\nTarget after one-hot-encoding:\\n----------------\")\n",
        "print(y_data[:5,:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbPmj34dG88d",
        "outputId": "102d8a4f-618e-4d6e-9ae7-18ddb4813ebe"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "features after scaling:\n",
            "----------------\n",
            "[[-0.13282213 -0.35013678  0.31258717 -0.01068969 -0.06185589 -0.5835852\n",
            "  -0.84831131 -0.45640248 -0.53104201 -0.48647252 -0.66193361 -0.49204509\n",
            "  -0.73434937  0.19050282 -0.37499162  0.37275672  0.00432643  0.12536307\n",
            "   0.30847037 -0.42744458  0.70309345 -0.93639809 -0.47269061 -0.81084363\n",
            "   0.36466458 -0.59684161 -0.42732103 -0.06423578  0.33717421 -0.55597237\n",
            "  -0.86315362 -0.8344325   0.49951802 -0.46959533 -0.63770406 -0.16118663\n",
            "   0.40925862 -0.49971511 -0.33836791 -0.36147796  0.64538476 -0.53441001\n",
            "   0.18219014 -0.80434978  0.79228723 -0.70309227 -0.26555766 -0.38652827\n",
            "  -0.08639575 -0.24611385  0.50046241 -0.78026476 -0.23704039 -0.64317667\n",
            "   0.00672291 -0.30059734  0.60406407 -0.51298758]]\n",
            "\n",
            "Target after one-hot-encoding:\n",
            "----------------\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split training and test data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size = 0.20)"
      ],
      "metadata": {
        "id": "8AO6GLW2ERT2"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTrain Test Dimension:\\n-----------\")\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "3-yESugrEsue",
        "outputId": "75557bdd-7ec7-4532-ff32-4ab3534bcf9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Test Dimension:\n",
            "-----------\n",
            "(800, 58) (800, 10) (200, 58) (200, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.regularizers import l2\n"
      ],
      "metadata": {
        "id": "mTQFDtm-H4bR"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup hyper parameters for deep learning\n",
        "EPOCHS = 15\n",
        "BATCH_SIZE = 16\n",
        "VERBOSE = 1\n",
        "NB_CLASSES = 10\n",
        "# N_HIDDEN = 128\n",
        "VALIDATION_SPLIT = 0.2"
      ],
      "metadata": {
        "id": "hoSuJ6T_Ir02"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a keras model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Add first hidden dense layer\n",
        "model.add(keras.layers.Dense(128,\n",
        "                             input_shape=(58,),\n",
        "                             name='Dense-layer-1',\n",
        "                             activation = 'relu'))"
      ],
      "metadata": {
        "id": "F6zsj3FyI9HH"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add second hidden layer\n",
        "model.add(keras.layers.Dense(128,\n",
        "                             name='Dense-layer-2',\n",
        "                             activation = 'relu'))"
      ],
      "metadata": {
        "id": "EErAtAiTJkxI"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add final layer with softmax\n",
        "model.add(keras.layers.Dense(NB_CLASSES,\n",
        "                             name='Final-layer',\n",
        "                             activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tH3Ypbq4JuL0",
        "outputId": "b33ee9cc-3ebb-42eb-b02f-a9cab55df449"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Dense-layer-1 (Dense)       (None, 128)               7552      \n",
            "                                                                 \n",
            " Dense-layer-2 (Dense)       (None, 128)               16512     \n",
            "                                                                 \n",
            " Final-layer (Dense)         (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,354\n",
            "Trainable params: 25,354\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "GrzF6pQ9Kjz1"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit parameters\n",
        "print(\"\\nTraining Progress:\\n------------------------\")\n",
        "history = model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=VERBOSE,\n",
        "          validation_split=VALIDATION_SPLIT)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z77XI0UqJ9ma",
        "outputId": "7c2d9973-55ec-4f79-e552-289025f8c1ba"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Progress:\n",
            "------------------------\n",
            "Epoch 1/15\n",
            "40/40 [==============================] - 1s 7ms/step - loss: 1.7831 - accuracy: 0.3859 - val_loss: 1.5277 - val_accuracy: 0.4375\n",
            "Epoch 2/15\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 1.1654 - accuracy: 0.6156 - val_loss: 1.2426 - val_accuracy: 0.5562\n",
            "Epoch 3/15\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.9024 - accuracy: 0.7063 - val_loss: 1.0772 - val_accuracy: 0.6313\n",
            "Epoch 4/15\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7250 - accuracy: 0.7891 - val_loss: 0.9695 - val_accuracy: 0.7063\n",
            "Epoch 5/15\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6032 - accuracy: 0.8188 - val_loss: 0.9264 - val_accuracy: 0.6875\n",
            "Epoch 6/15\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.8453 - val_loss: 0.8654 - val_accuracy: 0.7250\n",
            "Epoch 7/15\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.8813 - val_loss: 0.9029 - val_accuracy: 0.6875\n",
            "Epoch 8/15\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.3701 - accuracy: 0.8953 - val_loss: 0.8741 - val_accuracy: 0.7188\n",
            "Epoch 9/15\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.3154 - accuracy: 0.9203 - val_loss: 0.8893 - val_accuracy: 0.7375\n",
            "Epoch 10/15\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.2737 - accuracy: 0.9391 - val_loss: 0.8950 - val_accuracy: 0.7312\n",
            "Epoch 11/15\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.2341 - accuracy: 0.9500 - val_loss: 0.8866 - val_accuracy: 0.7437\n",
            "Epoch 12/15\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.1990 - accuracy: 0.9594 - val_loss: 0.8754 - val_accuracy: 0.7437\n",
            "Epoch 13/15\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.1729 - accuracy: 0.9703 - val_loss: 0.9575 - val_accuracy: 0.7437\n",
            "Epoch 14/15\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9766 - val_loss: 0.9201 - val_accuracy: 0.7500\n",
            "Epoch 15/15\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.1207 - accuracy: 0.9906 - val_loss: 0.9225 - val_accuracy: 0.7563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nAccuracy during Training :\\n-------------------\")\n",
        "import matplotlib.pyplot as plt\n",
        "pd.DataFrame(history.history)[\"accuracy\"].plot(figsize=(8,5))\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title(\"Accuracy improvements with Epoch\")\n",
        "plt.show()\n",
        "\n",
        "# Evaluate the model against the test dataset and print results\n",
        "print(\"\\nEvaluation against Test Dataset:\\n----------------\")\n",
        "model.evaluate(X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "mNr0SXvmLF1U",
        "outputId": "0196377f-15d9-4ee6-e50b-b9fad442e469"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy during Training :\n",
            "-------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation against Test Dataset:\n",
            "----------------\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.0528 - accuracy: 0.7050\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0528342723846436, 0.7049999833106995]"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_Z2o7ovBGziz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}